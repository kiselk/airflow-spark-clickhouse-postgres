{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f8bd0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+\n",
      "|            owner|                repo|\n",
      "+-----------------+--------------------+\n",
      "|        getpremia|         premia-demo|\n",
      "|       urbanailab|urbanailab.github.io|\n",
      "|       afzalali15|      FlutterTopFive|\n",
      "|        alamayreh|     VIPPGeo_Dataset|\n",
      "|    virtualstores|            ios-wifi|\n",
      "|       wiredtiger|          wiredtiger|\n",
      "|         Oztechan|                 CCC|\n",
      "|           pallih|                 rss|\n",
      "|         Su-Kyung|            Su-Kyung|\n",
      "|          lisi4ok|         phalcon-api|\n",
      "|          elastic|        integrations|\n",
      "|       ashish4907|              Spring|\n",
      "|  spring-projects|     spring-data-jpa|\n",
      "|        saucelabs|      saucerest-java|\n",
      "|          cdklabs| construct-hub-probe|\n",
      "| keshavjindal1235|           project20|\n",
      "|denniszhao-github|              config|\n",
      "|            zcash|             orchard|\n",
      "|    fresh-coupons|  fresh-coupons-data|\n",
      "|       ZeroDragon|          ZeroDragon|\n",
      "+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Create Spark Context\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession, functions\n",
    "from pyspark.sql.functions import col, split\n",
    "\n",
    "import requests\n",
    "#sc = SparkContext()\n",
    "spark = (SparkSession\n",
    "         .builder\n",
    "         .getOrCreate()\n",
    "         )\n",
    "sc = spark.sparkContext\n",
    "\n",
    "def download(date, hour):\n",
    "    prefix = date + '-' + str(hour)\n",
    "    url = 'https://data.gharchive.org/' + prefix + '.json.gz'\n",
    "    path = prefix + '.json.gz'\n",
    "    #response = requests.get(url, stream=True)\n",
    "    #open(path, 'wb').write(response.content)\n",
    "    return path\n",
    "\n",
    "\n",
    "file = download('2022-09-19', '12')\n",
    "json = spark.read.json(file)\n",
    "json.createOrReplaceTempView(\"github\")\n",
    "\n",
    "\n",
    "\n",
    "eventsDF = spark.sql(\"SELECT type,repo.name as owner_repo,actor.login as submitter FROM github\") \\\n",
    "        .withColumn(\"owner\", split(col(\"owner_repo\"),\"/\").getItem(0)) \\\n",
    "        .withColumn(\"repo\", split(col(\"owner_repo\"),\"/\").getItem(1)) \\\n",
    "        .drop(\"owner_repo\")\n",
    "\n",
    "                           \n",
    "# List of Developers that own more than one repository;\n",
    "eventsDF.drop('submitter','type').distinct().groupBy('owner').count().where(\"count > 1\").orderBy(col('count').desc())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6d0c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "82ed002fa2d4956f5c6aec99bcefe0f73a9f79882f3c9e2319b14958a5896ac5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
